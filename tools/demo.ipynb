{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f052650050e9bb5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aef68bd5f7d34c25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T02:55:16.302188Z",
     "start_time": "2023-12-13T02:55:16.293857Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f35a8c66ad3c817",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## MP4 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T02:55:33.541542Z",
     "start_time": "2023-12-13T02:55:33.460844Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import clear_output, display, HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "\n",
    "def play_video(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        clear_output(wait=True)\n",
    "        _, buffer = cv2.imencode('.jpg', frame)\n",
    "        display(HTML('<img src=\"data:image/jpeg;base64,{}\">'.format(b64encode(buffer).decode())))\n",
    "        # time.sleep(0.1)\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc3acf9ad573d4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data transform functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f5b0626c3104d09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T02:55:42.396579Z",
     "start_time": "2023-12-13T02:55:41.469121Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    ori_image = image.copy()\n",
    "    h, w = image.shape[:2]\n",
    "    scale = 800 / min(h, w)\n",
    "    if max(h, w) * scale > 1536:\n",
    "        scale = 1536 / max(h, w)\n",
    "    target_h = int(h * scale)\n",
    "    target_w = int(w * scale)\n",
    "    image = cv2.resize(image, (target_w, target_h))\n",
    "    image = F.normalize(F.to_tensor(image), [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    return image, ori_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0593605b6fa0fd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Tracking functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "569b8ba2c44f5424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T02:55:49.730740Z",
     "start_time": "2023-12-13T02:55:49.714150Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from structures.track_instances import TrackInstances\n",
    "\n",
    "\n",
    "def filter_by_score(tracks: TrackInstances, thresh: float = 0.7):\n",
    "    keep = torch.max(tracks.scores, dim=-1).values > thresh\n",
    "    return tracks[keep]\n",
    "\n",
    "def filter_by_area(tracks: TrackInstances, thresh: int = 100):\n",
    "    assert len(tracks.area) == len(tracks.ids), f\"Tracks' 'area' should have the same dim with 'ids'\"\n",
    "    keep = tracks.area > thresh\n",
    "    return tracks[keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb3a9aa4538cbc0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965b054a753963c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T02:55:53.026457Z",
     "start_time": "2023-12-13T02:55:53.002828Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def get_color(idx):\n",
    "    idx = idx * 3\n",
    "    color = ((37 * idx) % 255, (17 * idx) % 255, (29 * idx) % 255)\n",
    "\n",
    "    return color\n",
    "\n",
    "def plot_tracking(image, tlwhs, obj_ids, scores=None, frame_id=0, fps=0., ids2=None):\n",
    "    # Thanks to https://github.com/noahcao/OC_SORT\n",
    "    im = np.ascontiguousarray(np.copy(image))\n",
    "    im_h, im_w = im.shape[:2]\n",
    "\n",
    "    top_view = np.zeros([im_w, im_w, 3], dtype=np.uint8) + 255\n",
    "    text_scale = 2\n",
    "    text_thickness = 2\n",
    "    line_thickness = 3\n",
    "\n",
    "    radius = max(5, int(im_w/140.))\n",
    "    cv2.putText(im, 'frame: %d fps: %.2f num: %d' % (frame_id, fps, len(tlwhs)),\n",
    "                (0, int(15 * text_scale)), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), thickness=2)\n",
    "\n",
    "    for i, tlwh in enumerate(tlwhs):\n",
    "        x1, y1, w, h = tlwh\n",
    "        intbox = tuple(map(int, (x1, y1, x1 + w, y1 + h)))\n",
    "        obj_id = int(obj_ids[i])\n",
    "        id_text = '{}'.format(int(obj_id))\n",
    "        if ids2 is not None:\n",
    "            id_text = id_text + ', {}'.format(int(ids2[i]))\n",
    "        color = get_color(abs(obj_id))\n",
    "        cv2.rectangle(im, intbox[0:2], intbox[2:4], color=color, thickness=line_thickness)\n",
    "        cv2.putText(im, id_text, (intbox[0], intbox[1]), cv2.FONT_HERSHEY_PLAIN, text_scale, (0, 0, 255),\n",
    "                    thickness=text_thickness)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dbdcb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def cut_image_from_bbox( image, boxes):\n",
    "    left = torch.clamp(boxes[:, 0], 0).tolist()\n",
    "    top = torch.clamp(boxes[:, 1], 0).tolist()\n",
    "    right = torch.clamp(boxes[:, 2], 0).tolist()\n",
    "    bottom = torch.clamp(boxes[:, 3], 0).tolist()\n",
    "    cropped_image =[]\n",
    "    \n",
    "    for i in range(len(left)):\n",
    "        img=image.copy().crop((left[i], top[i], right[i], bottom[i]))\n",
    "        cropped_image.append(img)\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ea92028ff1606",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Demo (inference) functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32a65a3645349542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T02:56:18.720794Z",
     "start_time": "2023-12-13T02:56:18.689511Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os.path\n",
    "import sys\n",
    "import numpy as np\n",
    "from models import build_model\n",
    "from models.utils import load_checkpoint\n",
    "from utils.utils import yaml_to_dict\n",
    "\n",
    "import torch\n",
    "from typing import List\n",
    "from models import build_model\n",
    "from models.utils import load_checkpoint, get_model\n",
    "from models.runtime_tracker import RuntimeTracker\n",
    "from utils.utils import yaml_to_dict, is_distributed, distributed_world_size, distributed_rank, inverse_sigmoid\n",
    "from utils.nested_tensor import tensor_list_to_nested_tensor\n",
    "from utils.box_ops import box_cxcywh_to_xyxy\n",
    "from structures.track_instances import TrackInstances\n",
    "from models.ikun import tokenize, expression_conversion\n",
    "from models.visualize import Visualizer\n",
    "\n",
    "\n",
    "def demo_processing(\n",
    "        model_path: str,\n",
    "        config_path: str,\n",
    "        video_path: str,\n",
    "):\n",
    "    config = yaml_to_dict(config_path)\n",
    "    model = build_model(config)\n",
    "    load_checkpoint(\n",
    "        model=model,\n",
    "        path=model_path\n",
    "    )\n",
    "    model.eval()\n",
    "    print(\"Model loaded.\")\n",
    "    current_time = time.localtime()\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    timestamp = time.strftime(\"%Y_%m_%d_%H_%M_%S\", current_time)\n",
    "    save_folder = os.path.join(\"./cache/\", timestamp)\n",
    "    save_path = os.path.join(save_folder, \"output.avi\")\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    vid_writer = cv2.VideoWriter(\n",
    "        save_path, cv2.VideoWriter_fourcc(*\"MJPG\"), fps, (int(width), int(height))\n",
    "    )\n",
    "    print((int(width), int(height)))\n",
    "    visualizer = Visualizer(save_dir=\"D:\\Thesis\\DamnShit\\Hello\\MeMOTR_IKUN\\Visual\")   \n",
    "    result_score_thresh = 0.5\n",
    "\n",
    "    timer = Timer()\n",
    "    frame_id = 0\n",
    "\n",
    "\n",
    "    tracks = [TrackInstances(\n",
    "        hidden_dim=model.memotr_model.hidden_dim,\n",
    "        num_classes=model.memotr_model.num_classes,\n",
    "        use_dab=config[\"USE_DAB\"],\n",
    "    ).to(\"cuda\")]\n",
    "    tracker = RuntimeTracker(\n",
    "        det_score_thresh=0.5, \n",
    "        track_score_thresh=0.5,\n",
    "        miss_tolerance=30,\n",
    "        use_motion=False,\n",
    "        motion_min_length=0, \n",
    "        motion_max_length=0,\n",
    "        visualize=False, \n",
    "        use_dab=config[\"USE_DAB\"],\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            if frame_id % 20 == 0:\n",
    "                print('Processing frame {} ({:.2f} fps)'.format(frame_id, 1. / max(1e-5, timer.average_time)))\n",
    "            ret_val, ret_frame = cap.read()\n",
    "            # online_im = ret_frame\n",
    "            if ret_val:\n",
    "                image = process_image(ret_frame)\n",
    "                frame = tensor_list_to_nested_tensor([image[0]]).to(\"cuda\")\n",
    "                temp_img=Image.fromarray( np.asarray(cv2.cvtColor(ret_frame, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "                timer.tic()\n",
    "                res = model(frame=frame, tracks=tracks)\n",
    "                previous_tracks, new_tracks = tracker.update(\n",
    "                    model_outputs=res,\n",
    "                    tracks=tracks\n",
    "                )\n",
    "                remain_bbox= torch.cat([new_tracks[-1].boxes,previous_tracks[-1].boxes],dim=0)\n",
    "                boxes = box_cxcywh_to_xyxy(remain_bbox)\n",
    "                boxes = (boxes * torch.as_tensor([width,height, width, height], dtype=torch.float).to(boxes.device))\n",
    "           \n",
    "                crop_image=cut_image_from_bbox(temp_img,boxes)\n",
    "               \n",
    "                ikun_model=model.model4\n",
    "                # transform_ori_img = ikun_model.transform[2](temp_img)\n",
    "           \n",
    "                if len(crop_image)>0:\n",
    "                    probs = ikun_model(crop_image,\"man in black shirt\")\n",
    "                    # arr=[mask['logits'][0][i][i].item() for i in range(mask['logits'][0].shape[0])]\n",
    "                    # probs = torch.tensor(arr)\n",
    "                    visualizer(temp_img,boxes, \"man in black shirt\",probs)\n",
    "                # # self.visualizer(ori_img,tensorBoxes,sentences,torch.Tensor([]))\n",
    "                # if len(boxes) >0:\n",
    "                #     crop_image[0].show()\n",
    "                # print(previous_tracks[0])\n",
    "                tracks: List[TrackInstances] = model.memotr_model.postprocess_single_frame(previous_tracks, new_tracks, None)\n",
    "        \n",
    "                tracks_result = tracks[0].to(torch.device(\"cpu\"))\n",
    "                # ori_h, ori_w = ori_image.shape[1], ori_image.shape[2]\n",
    "                ori_h, ori_w = height, width\n",
    "                # box = [x, y, w, h]\n",
    "                tracks_result.area = tracks_result.boxes[:, 2] * ori_w * \\\n",
    "                                     tracks_result.boxes[:, 3] * ori_h\n",
    "                tracks_result = filter_by_score(tracks_result, thresh=result_score_thresh)\n",
    "                tracks_result = filter_by_area(tracks_result)\n",
    "                # to xyxy:\n",
    "                tracks_result.boxes = box_cxcywh_to_xyxy(tracks_result.boxes)\n",
    "                tracks_result.boxes = (tracks_result.boxes * torch.as_tensor([ori_w, ori_h, ori_w, ori_h], dtype=torch.float))\n",
    "                online_tlwhs, online_ids = [], []\n",
    "                for i in range(len(tracks_result)):\n",
    "                    x1, y1, x2, y2 = tracks_result.boxes[i].tolist()\n",
    "                    w, h = x2 - x1, y2 - y1\n",
    "                    online_tlwhs.append([x1, y1, w, h])\n",
    "                    online_ids.append(tracks_result.ids[i].item())\n",
    "                timer.toc()\n",
    "                if len(online_tlwhs) > 0:\n",
    "                    online_im = plot_tracking(\n",
    "                        ret_frame, online_tlwhs, online_ids, frame_id=frame_id + 1, fps=1. / timer.average_time\n",
    "                    )\n",
    "                else:\n",
    "                    online_im = ret_frame\n",
    "                vid_writer.write(online_im)\n",
    "                ch = cv2.waitKey(1)\n",
    "                if ch == 27 or ch == ord(\"q\") or ch == ord(\"Q\"):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "            frame_id += 1\n",
    "    return os.path.join(save_folder, \"output.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85ec00acf02136e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8ca3ad56dec58ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T02:56:23.670264Z",
     "start_time": "2023-12-13T02:56:23.428047Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Timer(object):\n",
    "    \"\"\"A simple timer.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.total_time = 0.\n",
    "        self.calls = 0\n",
    "        self.start_time = 0.\n",
    "        self.diff = 0.\n",
    "        self.average_time = 0.\n",
    "\n",
    "        self.duration = 0.\n",
    "\n",
    "    def tic(self):\n",
    "        # using time.time instead of time.clock because time time.clock\n",
    "        # does not normalize for multithreading\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def toc(self, average=True):\n",
    "        self.diff = time.time() - self.start_time\n",
    "        self.total_time += self.diff\n",
    "        self.calls += 1\n",
    "        self.average_time = self.total_time / self.calls\n",
    "        if average:\n",
    "            self.duration = self.average_time\n",
    "        else:\n",
    "            self.duration = self.diff\n",
    "        return self.duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf756a3b9164904",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe5dda17f6dcb2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Select demo mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6faff6cc699c1255",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_path = \"D:\\\\Thesis\\\\DamnShit\\\\Hello\\\\MeMOTR_IKUN\\\\test_occlusion2_test.mp4\"                                  # you should give me a mp4 file path\n",
    "config_path = \"..\\\\outputs\\\\memotr_mot17_coco\\\\train\\\\config.yaml\"          # the config path of model\n",
    "model_path = \"D:\\\\Thesis\\\\DamnShit\\\\Hello\\\\MeMOTR_IKUN\\\\memotr_mot17.pth\"       # the model checkpoint path\n",
    "\n",
    "# play_video(video_path)                                                  # play the video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed21dfb102cb17",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b007a0e351f8c38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T03:00:02.556214Z",
     "start_time": "2023-12-13T02:59:05.790611Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model is loaded, there are 0 parameters droped and 0 parameters unloaded, set 'show details' True to see more details.\n",
      "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_retrieval_flickr.pth\n",
      "Model loaded.\n",
      "(1280, 720)\n",
      "Processing frame 0 (100000.00 fps)\n",
      "Image saved at: picture_2024_05_27__14_09_50.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_08.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_18.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_21.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_24.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_27.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_30.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_33.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_36.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_39.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_42.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_44.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_46.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_48.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_51.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_54.jpg\n",
      "Image saved at: picture_2024_05_27__14_10_57.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_00.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_02.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_05.jpg\n",
      "Processing frame 20 (0.18 fps)\n",
      "Image saved at: picture_2024_05_27__14_11_08.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_11.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_14.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_17.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_20.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_23.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_26.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_29.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_32.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_35.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_38.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_41.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_43.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_46.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_49.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_52.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_55.jpg\n",
      "Image saved at: picture_2024_05_27__14_11_58.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_01.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_04.jpg\n",
      "Processing frame 40 (0.24 fps)\n",
      "Image saved at: picture_2024_05_27__14_12_07.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_10.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_13.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_16.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_19.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_22.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_24.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_27.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_30.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_32.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_35.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_38.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_40.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_43.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_45.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_48.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_51.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_53.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_56.jpg\n",
      "Image saved at: picture_2024_05_27__14_12_59.jpg\n",
      "Processing frame 60 (0.27 fps)\n",
      "Image saved at: picture_2024_05_27__14_13_01.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_04.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_06.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_09.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_12.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_14.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_17.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_20.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_22.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_25.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_28.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_30.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_33.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_35.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_38.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_41.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_43.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_46.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_49.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_51.jpg\n",
      "Processing frame 80 (0.29 fps)\n",
      "Image saved at: picture_2024_05_27__14_13_53.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_56.jpg\n",
      "Image saved at: picture_2024_05_27__14_13_58.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_01.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_03.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_05.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_07.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_10.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_12.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_14.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_17.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_19.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_21.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_24.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_26.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_29.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_31.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_32.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_34.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_36.jpg\n",
      "Processing frame 100 (0.32 fps)\n",
      "Image saved at: picture_2024_05_27__14_14_38.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_41.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_43.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_46.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_48.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_50.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_53.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_55.jpg\n",
      "Image saved at: picture_2024_05_27__14_14_57.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_00.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_02.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_04.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_07.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_09.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_12.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_14.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_16.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_19.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_21.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_23.jpg\n",
      "Processing frame 120 (0.33 fps)\n",
      "Image saved at: picture_2024_05_27__14_15_26.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_28.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_30.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_33.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_35.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_38.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_40.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_42.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_45.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_47.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_49.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_52.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_54.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_56.jpg\n",
      "Image saved at: picture_2024_05_27__14_15_59.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_01.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_03.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_06.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_08.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_10.jpg\n",
      "Processing frame 140 (0.34 fps)\n",
      "Image saved at: picture_2024_05_27__14_16_13.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_16.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_18.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_21.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_24.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_26.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_29.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_32.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_34.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_36.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_39.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_41.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_43.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_46.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_48.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_51.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_53.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_55.jpg\n",
      "Image saved at: picture_2024_05_27__14_16_58.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_00.jpg\n",
      "Processing frame 160 (0.35 fps)\n",
      "Image saved at: picture_2024_05_27__14_17_02.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_04.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_07.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_09.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_11.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_14.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_16.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_18.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_20.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_23.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_25.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_27.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_29.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_31.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_32.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_34.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_35.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_37.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_39.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_40.jpg\n",
      "Processing frame 180 (0.36 fps)\n",
      "Image saved at: picture_2024_05_27__14_17_42.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_44.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_45.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_47.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_49.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_50.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_52.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_53.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_55.jpg\n",
      "Image saved at: picture_2024_05_27__14_17_58.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_00.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_02.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_04.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_06.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_07.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_09.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_11.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_13.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_14.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_16.jpg\n",
      "Processing frame 200 (0.38 fps)\n",
      "Image saved at: picture_2024_05_27__14_18_18.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_20.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_22.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_24.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_25.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_27.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_29.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_31.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_32.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_34.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_36.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_38.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_39.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_41.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_43.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_45.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_46.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_48.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_50.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_52.jpg\n",
      "Processing frame 220 (0.39 fps)\n",
      "Image saved at: picture_2024_05_27__14_18_53.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_55.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_57.jpg\n",
      "Image saved at: picture_2024_05_27__14_18_59.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_01.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_03.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_05.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_06.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_08.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_10.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_11.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_13.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_14.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_16.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_18.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_19.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_21.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_22.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_24.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_26.jpg\n",
      "Processing frame 240 (0.40 fps)\n",
      "Image saved at: picture_2024_05_27__14_19_27.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_29.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_30.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_32.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_33.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_35.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_37.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_38.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_40.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_41.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_43.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_45.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_46.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_48.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_49.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_51.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_52.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_54.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_56.jpg\n",
      "Image saved at: picture_2024_05_27__14_19_58.jpg\n",
      "Processing frame 260 (0.41 fps)\n",
      "Image saved at: picture_2024_05_27__14_19_59.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_01.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_03.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_05.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_06.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_08.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_10.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_12.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_13.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_15.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_17.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_18.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_20.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_21.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_23.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_25.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_26.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_28.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_29.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_31.jpg\n",
      "Processing frame 280 (0.42 fps)\n",
      "Image saved at: picture_2024_05_27__14_20_33.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_34.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_36.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_37.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_39.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_41.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_42.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_44.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_45.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_47.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_49.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_50.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_52.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_53.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_55.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_56.jpg\n",
      "Image saved at: picture_2024_05_27__14_20_58.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_00.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_01.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_03.jpg\n",
      "Processing frame 300 (0.43 fps)\n",
      "Image saved at: picture_2024_05_27__14_21_04.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_06.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_07.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_09.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_11.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_12.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_14.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_15.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_17.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_19.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_20.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_22.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_24.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_25.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_27.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_28.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_30.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_31.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_33.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_35.jpg\n",
      "Processing frame 320 (0.44 fps)\n",
      "Image saved at: picture_2024_05_27__14_21_36.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_38.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_39.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_41.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_43.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_44.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_46.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_47.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_49.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_51.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_52.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_54.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_55.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_57.jpg\n",
      "Image saved at: picture_2024_05_27__14_21_58.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_00.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_02.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_03.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_05.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_06.jpg\n",
      "Processing frame 340 (0.45 fps)\n",
      "Image saved at: picture_2024_05_27__14_22_08.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_10.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_11.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_13.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_14.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_16.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_17.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_19.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_21.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_22.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_24.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_26.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_27.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_29.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_30.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_32.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_33.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_35.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_37.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_38.jpg\n",
      "Processing frame 360 (0.46 fps)\n",
      "Image saved at: picture_2024_05_27__14_22_40.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_41.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_43.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_45.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_46.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_48.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_49.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_51.jpg\n",
      "Image saved at: picture_2024_05_27__14_22_52.jpg\n"
     ]
    }
   ],
   "source": [
    "output_path = demo_processing(\n",
    "    model_path=model_path,\n",
    "    config_path=config_path,\n",
    "    video_path=video_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b677910bd2d04277",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# play_video(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf29590b82cf15b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
